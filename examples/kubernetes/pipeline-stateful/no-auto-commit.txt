Step 1/6 : FROM striot/striot-base:latest
 ---> 6ec8dfd662b3
Step 2/6 : WORKDIR /opt/node
 ---> Running in d200b5c3e129
Removing intermediate container d200b5c3e129
 ---> 5c65f3b56149
Step 3/6 : COPY . /opt/node
 ---> 73eb2c2e1ad9
Step 4/6 : RUN ghc node.hs
 ---> Running in 8212097af7b6
[1 of 1] Compiling Main             ( node.hs, node.o )
Linking node ...
Removing intermediate container 8212097af7b6
 ---> 0d5bdcc0e1e3
Step 5/6 : EXPOSE 9001
 ---> Running in 27fcdf754a60
Removing intermediate container 27fcdf754a60
 ---> b19270f847f2
Step 6/6 : CMD /opt/node/node
 ---> Running in 35c1d6460fe4
Removing intermediate container 35c1d6460fe4
 ---> 3b6807041261
Successfully built 3b6807041261
Successfully tagged pipeline-stateful_node3:latest
Step 1/5 : FROM striot/striot-base:latest
 ---> 6ec8dfd662b3
Step 2/5 : WORKDIR /opt/node
 ---> Using cache
 ---> 5c65f3b56149
Step 3/5 : COPY . /opt/node
 ---> 1a1b1d09983d
Step 4/5 : RUN ghc node.hs
 ---> Running in b76e29e70aca
[1 of 1] Compiling Main             ( node.hs, node.o )
Linking node ...
Removing intermediate container b76e29e70aca
 ---> 2196b29731e0
Step 5/5 : CMD /opt/node/node
 ---> Running in 21a5d870c9ba
Removing intermediate container 21a5d870c9ba
 ---> 81062ae353b1
Successfully built 81062ae353b1
Successfully tagged pipeline-stateful_node2:latest
Step 1/5 : FROM striot/striot-base:latest
 ---> 6ec8dfd662b3
Step 2/5 : WORKDIR /opt/node
 ---> Using cache
 ---> 5c65f3b56149
Step 3/5 : COPY . /opt/node
 ---> 4e5c56f4cac8
Step 4/5 : RUN ghc node.hs
 ---> Running in 42b8d1f3d5f5
[1 of 1] Compiling Main             ( node.hs, node.o )
Linking node ...
Removing intermediate container 42b8d1f3d5f5
 ---> 4c4335a2d111
Step 5/5 : CMD /opt/node/node
 ---> Running in a5458b89ec8e
Removing intermediate container a5458b89ec8e
 ---> b62e55c872f7
Successfully built b62e55c872f7
Successfully tagged pipeline-stateful_node1:latest
Step 1/5 : FROM striot/striot-base:latest
 ---> 6ec8dfd662b3
Step 2/5 : WORKDIR /opt/node
 ---> Using cache
 ---> 5c65f3b56149
Step 3/5 : COPY . /opt/node
 ---> 1df596b19932
Step 4/5 : RUN ghc node.hs
 ---> Running in 8e96cee4d048
[1 of 1] Compiling Main             ( node.hs, node.o )
Linking node ...
Removing intermediate container 8e96cee4d048
 ---> fbee7317d4cb
Step 5/5 : CMD /opt/node/node
 ---> Running in 569917a7a7fa
Removing intermediate container 569917a7a7fa
 ---> 0d5e9717b657
Successfully built 0d5e9717b657
Successfully tagged pipeline-stateful_manage-sender:latest
Attaching to pipeline-stateful_node3_1, pipeline-stateful_zookeeper_1, pipeline-stateful_kafka_1, pipeline-stateful_node2_1, pipeline-stateful_node1_1, pipeline-stateful_manage-sender_1
[36mkafka_1          |[0m waiting for kafka to be ready
[32mnode1_1          |[0m "create new producer"
[32mnode1_1          |[0m "runhandler producer"
[32mnode1_1          |[0m %3|1586801732.943|FAIL|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#192.168.80.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[32mnode1_1          |[0m %3|1586801732.943|ERROR|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#192.168.80.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[32mnode1_1          |[0m %3|1586801732.943|ERROR|rdkafka#producer-1| [thrd:kafka:9092/bootstrap]: 1/1 brokers are down
[36mkafka_1          |[0m Excluding KAFKA_HOME from broker config
[35mnode2_1          |[0m "create new consumer"
[35mnode2_1          |[0m %7|1586801732.221|MEMBERID|rdkafka#consumer-1| [thrd:app]: Group "striot_con_group": updating member id "(not-set)" -> ""
[35mnode2_1          |[0m %7|1586801732.221|WAKEUPFD|rdkafka#consumer-1| [thrd:app]: GroupCoordinator: Enabled low-latency ops queue wake-ups
[35mnode2_1          |[0m %7|1586801732.221|BROKER|rdkafka#consumer-1| [thrd:app]: GroupCoordinator: Added new broker with NodeId -1
[35mnode2_1          |[0m %7|1586801732.221|BRKMAIN|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Enter main broker thread
[35mnode2_1          |[0m %7|1586801732.221|BRKMAIN|rdkafka#consumer-1| [thrd::0/internal]: :0/internal: Enter main broker thread
[35mnode2_1          |[0m %7|1586801732.221|WAKEUPFD|rdkafka#consumer-1| [thrd:app]: kafka:9092/bootstrap: Enabled low-latency ops queue wake-ups
[35mnode2_1          |[0m %7|1586801732.221|BROKER|rdkafka#consumer-1| [thrd:app]: kafka:9092/bootstrap: Added new broker with NodeId -1
[35mnode2_1          |[0m %7|1586801732.221|INIT|rdkafka#consumer-1| [thrd:app]: librdkafka v1.4.0-RC4-selfstatic-test18 (0x1040005) rdkafka#consumer-1 initialized (builtin.features gzip,snappy,ssl,sasl,regex,lz4,sasl_gssapi,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer, GCC GXX PKGCONFIG INSTALL GNULD LIBDL PLUGINS ZLIB SSL SASL_CYRUS ZSTD HDRHISTOGRAM SYSLOG SNAPPY SOCKEM SASL_SCRAM SASL_OAUTHBEARER CRC32C_HW, debug 0xfffff)
[35mnode2_1          |[0m %7|1586801732.221|BRKMAIN|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enter main broker thread
[35mnode2_1          |[0m %7|1586801732.222|CGRPOP|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" received op SUBSCRIBE (v0) in state init (join state init, v1 vs 0)
[35mnode2_1          |[0m %7|1586801732.222|SUBSCRIBE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": subscribe to new subscription of 1 topics (join state init)
[35mnode2_1          |[0m %7|1586801732.222|UNSUBSCRIBE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": unsubscribe from current unset subscription of 0 topics (leave group=no, join state init, v1)
[35mnode2_1          |[0m %7|1586801732.222|GRPLEADER|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": resetting group leader info: unsubscribe
[35mnode2_1          |[0m %7|1586801732.222|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" is rebalancing in state init (join-state init) without assignment: unsubscribe
[35mnode2_1          |[0m %7|1586801732.222|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state init -> wait-unassign (v1, state init)
[35mnode2_1          |[0m %7|1586801732.222|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": unassign done in state init (join state wait-unassign): without new assignment: unassign (no previous assignment)
[35mnode2_1          |[0m %7|1586801732.222|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-unassign -> init (v1, state init)
[35mnode2_1          |[0m %7|1586801732.222|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state init -> query-coord (v1, join-state init)
[35mnode2_1          |[0m %7|1586801732.222|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801732.222|CONNECT|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: Selected for cluster connection: coordinator query (broker has 0 connection attempt(s))
[35mnode2_1          |[0m "runhandler consumer"
[35mnode2_1          |[0m "{1}: Retrieve Input"
[35mnode2_1          |[0m %7|1586801732.222|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": no broker available for coordinator query: intervaled in state query-coord
[35mnode2_1          |[0m %7|1586801732.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Received CONNECT op
[35mnode2_1          |[0m "{2}: Perform streamOp"
[35mnode2_1          |[0m %7|1586801732.222|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state INIT -> TRY_CONNECT
[35mnode2_1          |[0m %7|1586801732.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801732.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: broker in state TRY_CONNECT connecting
[35mnode2_1          |[0m %7|1586801732.222|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state TRY_CONNECT -> CONNECT
[35mnode2_1          |[0m %7|1586801732.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[36mkafka_1          |[0m [Configuring] 'advertised.host.name' in '/opt/kafka/config/server.properties'
[35mnode2_1          |[0m %7|1586801732.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connecting to ipv4#192.168.80.3:9092 (plaintext) with socket 10
[35mnode2_1          |[0m %7|1586801732.222|BROKERFAIL|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection refused)
[35mnode2_1          |[0m %3|1586801732.222|FAIL|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#192.168.80.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mnode2_1          |[0m %3|1586801732.222|ERROR|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#192.168.80.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mnode2_1          |[0m %7|1586801732.222|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state CONNECT -> DOWN
[35mnode2_1          |[0m %3|1586801732.222|ERROR|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: 1/1 brokers are down
[35mnode2_1          |[0m %7|1586801732.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801732.222|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801732.223|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801732.223|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Updating 0 buffers on connection reset
[35mnode2_1          |[0m %7|1586801732.223|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state DOWN -> INIT
[35mnode2_1          |[0m %7|1586801732.223|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801733.221|CONNECT|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: Selected for cluster connection: coordinator query (broker has 1 connection attempt(s))
[35mnode2_1          |[0m %7|1586801733.221|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": no broker available for coordinator query: intervaled in state query-coord
[35mnode2_1          |[0m %7|1586801733.221|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Received CONNECT op
[35mnode2_1          |[0m %7|1586801733.221|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state INIT -> TRY_CONNECT
[35mnode2_1          |[0m %7|1586801733.221|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801733.221|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: broker in state TRY_CONNECT connecting
[35mnode2_1          |[0m %7|1586801733.221|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state TRY_CONNECT -> CONNECT
[35mnode2_1          |[0m %7|1586801733.221|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801733.221|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connecting to ipv4#192.168.80.3:9092 (plaintext) with socket 10
[35mnode2_1          |[0m %7|1586801733.221|BROKERFAIL|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection refused)
[35mnode2_1          |[0m %7|1586801733.221|FAIL|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connect to ipv4#192.168.80.3:9092 failed: Connection refused (after 0ms in state CONNECT)
[35mnode2_1          |[0m %7|1586801733.221|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state CONNECT -> DOWN
[35mnode2_1          |[0m %7|1586801733.221|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801733.221|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801733.221|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801733.221|BUFQ|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Updating 0 buffers on connection reset
[35mnode2_1          |[0m %7|1586801733.221|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state DOWN -> INIT
[35mnode2_1          |[0m %7|1586801733.221|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[36;1mzookeeper_1      |[0m ZooKeeper JMX enabled by default
[35mnode2_1          |[0m %7|1586801733.221|CONNECT|rdkafka#consumer-1| [thrd:main]: Not selecting any broker for cluster connection: still suppressed for 49ms: no cluster connection
[36mkafka_1          |[0m [Configuring] 'port' in '/opt/kafka/config/server.properties'
[36mkafka_1          |[0m [Configuring] 'broker.id' in '/opt/kafka/config/server.properties'
[36;1mzookeeper_1      |[0m Using config: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[36mkafka_1          |[0m Excluding KAFKA_VERSION from broker config
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,843 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,847 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
[36mkafka_1          |[0m [Configuring] 'zookeeper.connect' in '/opt/kafka/config/server.properties'
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,847 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
[36mkafka_1          |[0m [Configuring] 'log.dirs' in '/opt/kafka/config/server.properties'
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,848 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
[36mkafka_1          |[0m [2020-04-13 18:15:32,318] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[36mkafka_1          |[0m [2020-04-13 18:15:32,850] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[36mkafka_1          |[0m [2020-04-13 18:15:32,850] INFO starting (kafka.server.KafkaServer)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,848 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
[36mkafka_1          |[0m [2020-04-13 18:15:32,851] INFO Connecting to zookeeper on zookeeper:2181 (kafka.server.KafkaServer)
[36mkafka_1          |[0m [2020-04-13 18:15:32,869] INFO [ZooKeeperClient Kafka server] Initializing a new session to zookeeper:2181. (kafka.zookeeper.ZooKeeperClient)
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:host.name=bfe30d3c8c3c (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,858 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /opt/zookeeper-3.4.13/bin/../conf/zoo.cfg
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:java.version=1.8.0_212 (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,859 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,859 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:java.vendor=IcedTea (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 04:05 GMT
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:java.home=/usr/lib/jvm/java-1.8-openjdk/jre (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=58ba16b3b91e
[36mkafka_1          |[0m [2020-04-13 18:15:32,874] INFO Client environment:java.class.path=/opt/kafka/bin/../libs/activation-1.1.1.jar:/opt/kafka/bin/../libs/aopalliance-repackaged-2.5.0.jar:/opt/kafka/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka/bin/../libs/commons-cli-1.4.jar:/opt/kafka/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka/bin/../libs/connect-api-2.4.1.jar:/opt/kafka/bin/../libs/connect-basic-auth-extension-2.4.1.jar:/opt/kafka/bin/../libs/connect-file-2.4.1.jar:/opt/kafka/bin/../libs/connect-json-2.4.1.jar:/opt/kafka/bin/../libs/connect-mirror-2.4.1.jar:/opt/kafka/bin/../libs/connect-mirror-client-2.4.1.jar:/opt/kafka/bin/../libs/connect-runtime-2.4.1.jar:/opt/kafka/bin/../libs/connect-transforms-2.4.1.jar:/opt/kafka/bin/../libs/guava-20.0.jar:/opt/kafka/bin/../libs/hk2-api-2.5.0.jar:/opt/kafka/bin/../libs/hk2-locator-2.5.0.jar:/opt/kafka/bin/../libs/hk2-utils-2.5.0.jar:/opt/kafka/bin/../libs/jackson-annotations-2.10.0.jar:/opt/kafka/bin/../libs/jackson-core-2.10.0.jar:/opt/kafka/bin/../libs/jackson-databind-2.10.0.jar:/opt/kafka/bin/../libs/jackson-dataformat-csv-2.10.0.jar:/opt/kafka/bin/../libs/jackson-datatype-jdk8-2.10.0.jar:/opt/kafka/bin/../libs/jackson-jaxrs-base-2.10.0.jar:/opt/kafka/bin/../libs/jackson-jaxrs-json-provider-2.10.0.jar:/opt/kafka/bin/../libs/jackson-module-jaxb-annotations-2.10.0.jar:/opt/kafka/bin/../libs/jackson-module-paranamer-2.10.0.jar:/opt/kafka/bin/../libs/jackson-module-scala_2.12-2.10.0.jar:/opt/kafka/bin/../libs/jakarta.activation-api-1.2.1.jar:/opt/kafka/bin/../libs/jakarta.annotation-api-1.3.4.jar:/opt/kafka/bin/../libs/jakarta.inject-2.5.0.jar:/opt/kafka/bin/../libs/jakarta.ws.rs-api-2.1.5.jar:/opt/kafka/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/opt/kafka/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka/bin/../libs/jersey-client-2.28.jar:/opt/kafka/bin/../libs/jersey-common-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-2.28.jar:/opt/kafka/bin/../libs/jersey-container-servlet-core-2.28.jar:/opt/kafka/bin/../libs/jersey-hk2-2.28.jar:/opt/kafka/bin/../libs/jersey-media-jaxb-2.28.jar:/opt/kafka/bin/../libs/jersey-server-2.28.jar:/opt/kafka/bin/../libs/jetty-client-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-continuation-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-http-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-io-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-security-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-server-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-servlet-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-servlets-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jetty-util-9.4.20.v20190813.jar:/opt/kafka/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka/bin/../libs/kafka-clients-2.4.1.jar:/opt/kafka/bin/../libs/kafka-log4j-appender-2.4.1.jar:/opt/kafka/bin/../libs/kafka-streams-2.4.1.jar:/opt/kafka/bin/../libs/kafka-streams-examples-2.4.1.jar:/opt/kafka/bin/../libs/kafka-streams-scala_2.12-2.4.1.jar:/opt/kafka/bin/../libs/kafka-streams-test-utils-2.4.1.jar:/opt/kafka/bin/../libs/kafka-tools-2.4.1.jar:/opt/kafka/bin/../libs/kafka_2.12-2.4.1-sources.jar:/opt/kafka/bin/../libs/kafka_2.12-2.4.1.jar:/opt/kafka/bin/../libs/log4j-1.2.17.jar:/opt/kafka/bin/../libs/lz4-java-1.6.0.jar:/opt/kafka/bin/../libs/maven-artifact-3.6.1.jar:/opt/kafka/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka/bin/../libs/netty-buffer-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-codec-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-handler-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-resolver-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-epoll-4.1.45.Final.jar:/opt/kafka/bin/../libs/netty-transport-native-unix-common-4.1.45.Final.jar:/opt/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka/bin/../libs/paranamer-2.8.jar:/opt/kafka/bin/../libs/plexus-utils-3.2.0.jar:/opt/kafka/bin/../libs/reflections-0.9.11.jar:/opt/kafka/bin/../libs/rocksdbjni-5.18.3.jar:/opt/kafka/bin/../libs/scala-collection-compat_2.12-2.1.2.jar:/opt/kafka/bin/../libs/scala-java8-compat_2.12-0.9.0.jar:/opt/kafka/bin/../libs/scala-library-2.12.10.jar:/opt/kafka/bin/../libs/scala-logging_2.12-3.9.2.jar:/opt/kafka/bin/../libs/scala-reflect-2.12.10.jar:/opt/kafka/bin/../libs/slf4j-api-1.7.28.jar:/opt/kafka/bin/../libs/slf4j-log4j12-1.7.28.jar:/opt/kafka/bin/../libs/snappy-java-1.1.7.3.jar:/opt/kafka/bin/../libs/validation-api-2.0.1.Final.jar:/opt/kafka/bin/../libs/zookeeper-3.5.7.jar:/opt/kafka/bin/../libs/zookeeper-jute-3.5.7.jar:/opt/kafka/bin/../libs/zstd-jni-1.4.3-1.jar (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:java.library.path=/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,868 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.13/bin/../build/classes:/opt/zookeeper-3.4.13/bin/../build/lib/*.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-log4j12-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/slf4j-api-1.7.25.jar:/opt/zookeeper-3.4.13/bin/../lib/netty-3.10.6.Final.jar:/opt/zookeeper-3.4.13/bin/../lib/log4j-1.2.17.jar:/opt/zookeeper-3.4.13/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.13/bin/../lib/audience-annotations-0.5.0.jar:/opt/zookeeper-3.4.13/bin/../zookeeper-3.4.13.jar:/opt/zookeeper-3.4.13/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.13/bin/../conf:
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,869 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,869 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.version=5.5.16-1-MANJARO (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:user.name=root (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:user.home=/root (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:user.dir=/ (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,871 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.memory.free=979MB (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,875] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[36mkafka_1          |[0m [2020-04-13 18:15:32,877] INFO Initiating client connection, connectString=zookeeper:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@3d51f06e (org.apache.zookeeper.ZooKeeper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,871 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
[36mkafka_1          |[0m [2020-04-13 18:15:32,882] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[36mkafka_1          |[0m [2020-04-13 18:15:32,886] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[36mkafka_1          |[0m [2020-04-13 18:15:32,892] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[36mkafka_1          |[0m [2020-04-13 18:15:32,894] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[36mkafka_1          |[0m [2020-04-13 18:15:32,903] INFO Opening socket connection to server zookeeper/192.168.80.4:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,872 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
[36mkafka_1          |[0m [2020-04-13 18:15:32,908] INFO Socket connection established, initiating session, client: /192.168.80.3:43778, server: zookeeper/192.168.80.4:2181 (org.apache.zookeeper.ClientCnxn)
[36mkafka_1          |[0m [2020-04-13 18:15:32,935] INFO Session establishment complete on server zookeeper/192.168.80.4:2181, sessionid = 0x100004f727c0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[36mkafka_1          |[0m [2020-04-13 18:15:32,941] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,872 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.5.16-1-MANJARO
[36mkafka_1          |[0m [2020-04-13 18:15:33,291] INFO Cluster ID = JDtSBRIhRFipFkhscA09EQ (kafka.server.KafkaServer)
[36mkafka_1          |[0m [2020-04-13 18:15:33,296] WARN No meta.properties file under dir /kafka/kafka-logs-bfe30d3c8c3c/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[36mkafka_1          |[0m [2020-04-13 18:15:33,375] INFO KafkaConfig values: 
[36mkafka_1          |[0m 	advertised.host.name = kafka
[36mkafka_1          |[0m 	advertised.listeners = null
[36mkafka_1          |[0m 	advertised.port = null
[36mkafka_1          |[0m 	alter.config.policy.class.name = null
[36mkafka_1          |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36mkafka_1          |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36mkafka_1          |[0m 	authorizer.class.name = 
[36mkafka_1          |[0m 	auto.create.topics.enable = true
[36mkafka_1          |[0m 	auto.leader.rebalance.enable = true
[36mkafka_1          |[0m 	background.threads = 10
[36mkafka_1          |[0m 	broker.id = -1
[36mkafka_1          |[0m 	broker.id.generation.enable = true
[36mkafka_1          |[0m 	broker.rack = null
[36mkafka_1          |[0m 	client.quota.callback.class = null
[36mkafka_1          |[0m 	compression.type = producer
[36mkafka_1          |[0m 	connection.failed.authentication.delay.ms = 100
[36mkafka_1          |[0m 	connections.max.idle.ms = 600000
[36mkafka_1          |[0m 	connections.max.reauth.ms = 0
[36mkafka_1          |[0m 	control.plane.listener.name = null
[36mkafka_1          |[0m 	controlled.shutdown.enable = true
[36mkafka_1          |[0m 	controlled.shutdown.max.retries = 3
[36mkafka_1          |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mkafka_1          |[0m 	controller.socket.timeout.ms = 30000
[36mkafka_1          |[0m 	create.topic.policy.class.name = null
[36mkafka_1          |[0m 	default.replication.factor = 1
[36mkafka_1          |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36mkafka_1          |[0m 	delegation.token.expiry.time.ms = 86400000
[36mkafka_1          |[0m 	delegation.token.master.key = null
[36mkafka_1          |[0m 	delegation.token.max.lifetime.ms = 604800000
[36mkafka_1          |[0m 	delete.records.purgatory.purge.interval.requests = 1
[36mkafka_1          |[0m 	delete.topic.enable = true
[36mkafka_1          |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mkafka_1          |[0m 	group.initial.rebalance.delay.ms = 0
[36mkafka_1          |[0m 	group.max.session.timeout.ms = 1800000
[36mkafka_1          |[0m 	group.max.size = 2147483647
[36mkafka_1          |[0m 	group.min.session.timeout.ms = 6000
[36mkafka_1          |[0m 	host.name = 
[36mkafka_1          |[0m 	inter.broker.listener.name = null
[36mkafka_1          |[0m 	inter.broker.protocol.version = 2.4-IV1
[36mkafka_1          |[0m 	kafka.metrics.polling.interval.secs = 10
[36mkafka_1          |[0m 	kafka.metrics.reporters = []
[36mkafka_1          |[0m 	leader.imbalance.check.interval.seconds = 300
[36mkafka_1          |[0m 	leader.imbalance.per.broker.percentage = 10
[36mkafka_1          |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[36mkafka_1          |[0m 	listeners = null
[36mkafka_1          |[0m 	log.cleaner.backoff.ms = 15000
[36mkafka_1          |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mkafka_1          |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mkafka_1          |[0m 	log.cleaner.enable = true
[36mkafka_1          |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mkafka_1          |[0m 	log.cleaner.io.buffer.size = 524288
[36mkafka_1          |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mkafka_1          |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mkafka_1          |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36mkafka_1          |[0m 	log.cleaner.threads = 1
[36mkafka_1          |[0m 	log.cleanup.policy = [delete]
[36mkafka_1          |[0m 	log.dir = /tmp/kafka-logs
[36mkafka_1          |[0m 	log.dirs = /kafka/kafka-logs-bfe30d3c8c3c
[36mkafka_1          |[0m 	log.flush.interval.messages = 9223372036854775807
[36mkafka_1          |[0m 	log.flush.interval.ms = null
[36mkafka_1          |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mkafka_1          |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[36mkafka_1          |[0m 	log.index.interval.bytes = 4096
[36mkafka_1          |[0m 	log.index.size.max.bytes = 10485760
[36mkafka_1          |[0m 	log.message.downconversion.enable = true
[36mkafka_1          |[0m 	log.message.format.version = 2.4-IV1
[36mkafka_1          |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.message.timestamp.type = CreateTime
[36mkafka_1          |[0m 	log.preallocate = false
[36mkafka_1          |[0m 	log.retention.bytes = -1
[36mkafka_1          |[0m 	log.retention.check.interval.ms = 300000
[36mkafka_1          |[0m 	log.retention.hours = 168
[36mkafka_1          |[0m 	log.retention.minutes = null
[36mkafka_1          |[0m 	log.retention.ms = null
[36mkafka_1          |[0m 	log.roll.hours = 168
[36mkafka_1          |[0m 	log.roll.jitter.hours = 0
[36mkafka_1          |[0m 	log.roll.jitter.ms = null
[36mkafka_1          |[0m 	log.roll.ms = null
[36mkafka_1          |[0m 	log.segment.bytes = 1073741824
[36mkafka_1          |[0m 	log.segment.delete.delay.ms = 60000
[36mkafka_1          |[0m 	max.connections = 2147483647
[36mkafka_1          |[0m 	max.connections.per.ip = 2147483647
[36mkafka_1          |[0m 	max.connections.per.ip.overrides = 
[36mkafka_1          |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36mkafka_1          |[0m 	message.max.bytes = 1000012
[36mkafka_1          |[0m 	metric.reporters = []
[36mkafka_1          |[0m 	metrics.num.samples = 2
[36mkafka_1          |[0m 	metrics.recording.level = INFO
[36mkafka_1          |[0m 	metrics.sample.window.ms = 30000
[36mkafka_1          |[0m 	min.insync.replicas = 1
[36mkafka_1          |[0m 	num.io.threads = 8
[36mkafka_1          |[0m 	num.network.threads = 3
[36mkafka_1          |[0m 	num.partitions = 1
[36mkafka_1          |[0m 	num.recovery.threads.per.data.dir = 1
[36mkafka_1          |[0m 	num.replica.alter.log.dirs.threads = null
[36mkafka_1          |[0m 	num.replica.fetchers = 1
[36mkafka_1          |[0m 	offset.metadata.max.bytes = 4096
[36mkafka_1          |[0m 	offsets.commit.required.acks = -1
[36mkafka_1          |[0m 	offsets.commit.timeout.ms = 5000
[36mkafka_1          |[0m 	offsets.load.buffer.size = 5242880
[36mkafka_1          |[0m 	offsets.retention.check.interval.ms = 600000
[36mkafka_1          |[0m 	offsets.retention.minutes = 10080
[36mkafka_1          |[0m 	offsets.topic.compression.codec = 0
[36mkafka_1          |[0m 	offsets.topic.num.partitions = 50
[36mkafka_1          |[0m 	offsets.topic.replication.factor = 1
[36mkafka_1          |[0m 	offsets.topic.segment.bytes = 104857600
[36mkafka_1          |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36mkafka_1          |[0m 	password.encoder.iterations = 4096
[36mkafka_1          |[0m 	password.encoder.key.length = 128
[36mkafka_1          |[0m 	password.encoder.keyfactory.algorithm = null
[36mkafka_1          |[0m 	password.encoder.old.secret = null
[36mkafka_1          |[0m 	password.encoder.secret = null
[36mkafka_1          |[0m 	port = 9092
[36mkafka_1          |[0m 	principal.builder.class = null
[36mkafka_1          |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mkafka_1          |[0m 	queued.max.request.bytes = -1
[36mkafka_1          |[0m 	queued.max.requests = 500
[36mkafka_1          |[0m 	quota.consumer.default = 9223372036854775807
[36mkafka_1          |[0m 	quota.producer.default = 9223372036854775807
[36mkafka_1          |[0m 	quota.window.num = 11
[36mkafka_1          |[0m 	quota.window.size.seconds = 1
[36mkafka_1          |[0m 	replica.fetch.backoff.ms = 1000
[36mkafka_1          |[0m 	replica.fetch.max.bytes = 1048576
[36mkafka_1          |[0m 	replica.fetch.min.bytes = 1
[36mkafka_1          |[0m 	replica.fetch.response.max.bytes = 10485760
[36mkafka_1          |[0m 	replica.fetch.wait.max.ms = 500
[36mkafka_1          |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mkafka_1          |[0m 	replica.lag.time.max.ms = 10000
[36mkafka_1          |[0m 	replica.selector.class = null
[36mkafka_1          |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mkafka_1          |[0m 	replica.socket.timeout.ms = 30000
[36mkafka_1          |[0m 	replication.quota.window.num = 11
[36mkafka_1          |[0m 	replication.quota.window.size.seconds = 1
[36mkafka_1          |[0m 	request.timeout.ms = 30000
[36mkafka_1          |[0m 	reserved.broker.max.id = 1000
[36mkafka_1          |[0m 	sasl.client.callback.handler.class = null
[36mkafka_1          |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mkafka_1          |[0m 	sasl.jaas.config = null
[36mkafka_1          |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka_1          |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka_1          |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mkafka_1          |[0m 	sasl.kerberos.service.name = null
[36mkafka_1          |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka_1          |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka_1          |[0m 	sasl.login.callback.handler.class = null
[36mkafka_1          |[0m 	sasl.login.class = null
[36mkafka_1          |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka_1          |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka_1          |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka_1          |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka_1          |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mkafka_1          |[0m 	sasl.server.callback.handler.class = null
[36mkafka_1          |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mkafka_1          |[0m 	security.providers = null
[36mkafka_1          |[0m 	socket.receive.buffer.bytes = 102400
[36mkafka_1          |[0m 	socket.request.max.bytes = 104857600
[36mkafka_1          |[0m 	socket.send.buffer.bytes = 102400
[36mkafka_1          |[0m 	ssl.cipher.suites = []
[36mkafka_1          |[0m 	ssl.client.auth = none
[36mkafka_1          |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka_1          |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka_1          |[0m 	ssl.key.password = null
[36mkafka_1          |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka_1          |[0m 	ssl.keystore.location = null
[36mkafka_1          |[0m 	ssl.keystore.password = null
[36mkafka_1          |[0m 	ssl.keystore.type = JKS
[36mkafka_1          |[0m 	ssl.principal.mapping.rules = DEFAULT
[36mkafka_1          |[0m 	ssl.protocol = TLS
[36mkafka_1          |[0m 	ssl.provider = null
[36mkafka_1          |[0m 	ssl.secure.random.implementation = null
[36mkafka_1          |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka_1          |[0m 	ssl.truststore.location = null
[36mkafka_1          |[0m 	ssl.truststore.password = null
[36mkafka_1          |[0m 	ssl.truststore.type = JKS
[36mkafka_1          |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[36mkafka_1          |[0m 	transaction.max.timeout.ms = 900000
[36mkafka_1          |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[36mkafka_1          |[0m 	transaction.state.log.load.buffer.size = 5242880
[36mkafka_1          |[0m 	transaction.state.log.min.isr = 1
[36mkafka_1          |[0m 	transaction.state.log.num.partitions = 50
[36mkafka_1          |[0m 	transaction.state.log.replication.factor = 1
[36mkafka_1          |[0m 	transaction.state.log.segment.bytes = 104857600
[36mkafka_1          |[0m 	transactional.id.expiration.ms = 604800000
[36mkafka_1          |[0m 	unclean.leader.election.enable = false
[36mkafka_1          |[0m 	zookeeper.connect = zookeeper:2181
[36mkafka_1          |[0m 	zookeeper.connection.timeout.ms = 6000
[36mkafka_1          |[0m 	zookeeper.max.in.flight.requests = 10
[36mkafka_1          |[0m 	zookeeper.session.timeout.ms = 6000
[36mkafka_1          |[0m 	zookeeper.set.acl = false
[36mkafka_1          |[0m 	zookeeper.sync.time.ms = 2000
[36mkafka_1          |[0m  (kafka.server.KafkaConfig)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,872 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
[36mkafka_1          |[0m [2020-04-13 18:15:33,389] INFO KafkaConfig values: 
[36mkafka_1          |[0m 	advertised.host.name = kafka
[36mkafka_1          |[0m 	advertised.listeners = null
[36mkafka_1          |[0m 	advertised.port = null
[36mkafka_1          |[0m 	alter.config.policy.class.name = null
[36mkafka_1          |[0m 	alter.log.dirs.replication.quota.window.num = 11
[36mkafka_1          |[0m 	alter.log.dirs.replication.quota.window.size.seconds = 1
[36mkafka_1          |[0m 	authorizer.class.name = 
[36mkafka_1          |[0m 	auto.create.topics.enable = true
[36mkafka_1          |[0m 	auto.leader.rebalance.enable = true
[36mkafka_1          |[0m 	background.threads = 10
[36mkafka_1          |[0m 	broker.id = -1
[36mkafka_1          |[0m 	broker.id.generation.enable = true
[36mkafka_1          |[0m 	broker.rack = null
[36mkafka_1          |[0m 	client.quota.callback.class = null
[36mkafka_1          |[0m 	compression.type = producer
[36mkafka_1          |[0m 	connection.failed.authentication.delay.ms = 100
[36mkafka_1          |[0m 	connections.max.idle.ms = 600000
[36mkafka_1          |[0m 	connections.max.reauth.ms = 0
[36mkafka_1          |[0m 	control.plane.listener.name = null
[36mkafka_1          |[0m 	controlled.shutdown.enable = true
[36mkafka_1          |[0m 	controlled.shutdown.max.retries = 3
[36mkafka_1          |[0m 	controlled.shutdown.retry.backoff.ms = 5000
[36mkafka_1          |[0m 	controller.socket.timeout.ms = 30000
[36mkafka_1          |[0m 	create.topic.policy.class.name = null
[36mkafka_1          |[0m 	default.replication.factor = 1
[36mkafka_1          |[0m 	delegation.token.expiry.check.interval.ms = 3600000
[36mkafka_1          |[0m 	delegation.token.expiry.time.ms = 86400000
[36mkafka_1          |[0m 	delegation.token.master.key = null
[36mkafka_1          |[0m 	delegation.token.max.lifetime.ms = 604800000
[36mkafka_1          |[0m 	delete.records.purgatory.purge.interval.requests = 1
[36mkafka_1          |[0m 	delete.topic.enable = true
[36mkafka_1          |[0m 	fetch.purgatory.purge.interval.requests = 1000
[36mkafka_1          |[0m 	group.initial.rebalance.delay.ms = 0
[36mkafka_1          |[0m 	group.max.session.timeout.ms = 1800000
[36mkafka_1          |[0m 	group.max.size = 2147483647
[36mkafka_1          |[0m 	group.min.session.timeout.ms = 6000
[36mkafka_1          |[0m 	host.name = 
[36mkafka_1          |[0m 	inter.broker.listener.name = null
[36mkafka_1          |[0m 	inter.broker.protocol.version = 2.4-IV1
[36mkafka_1          |[0m 	kafka.metrics.polling.interval.secs = 10
[36mkafka_1          |[0m 	kafka.metrics.reporters = []
[36mkafka_1          |[0m 	leader.imbalance.check.interval.seconds = 300
[36mkafka_1          |[0m 	leader.imbalance.per.broker.percentage = 10
[36mkafka_1          |[0m 	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
[36mkafka_1          |[0m 	listeners = null
[36mkafka_1          |[0m 	log.cleaner.backoff.ms = 15000
[36mkafka_1          |[0m 	log.cleaner.dedupe.buffer.size = 134217728
[36mkafka_1          |[0m 	log.cleaner.delete.retention.ms = 86400000
[36mkafka_1          |[0m 	log.cleaner.enable = true
[36mkafka_1          |[0m 	log.cleaner.io.buffer.load.factor = 0.9
[36mkafka_1          |[0m 	log.cleaner.io.buffer.size = 524288
[36mkafka_1          |[0m 	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
[36mkafka_1          |[0m 	log.cleaner.max.compaction.lag.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.cleaner.min.cleanable.ratio = 0.5
[36mkafka_1          |[0m 	log.cleaner.min.compaction.lag.ms = 0
[36mkafka_1          |[0m 	log.cleaner.threads = 1
[36mkafka_1          |[0m 	log.cleanup.policy = [delete]
[36mkafka_1          |[0m 	log.dir = /tmp/kafka-logs
[36mkafka_1          |[0m 	log.dirs = /kafka/kafka-logs-bfe30d3c8c3c
[36mkafka_1          |[0m 	log.flush.interval.messages = 9223372036854775807
[36mkafka_1          |[0m 	log.flush.interval.ms = null
[36mkafka_1          |[0m 	log.flush.offset.checkpoint.interval.ms = 60000
[36mkafka_1          |[0m 	log.flush.scheduler.interval.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.flush.start.offset.checkpoint.interval.ms = 60000
[36mkafka_1          |[0m 	log.index.interval.bytes = 4096
[36mkafka_1          |[0m 	log.index.size.max.bytes = 10485760
[36mkafka_1          |[0m 	log.message.downconversion.enable = true
[36mkafka_1          |[0m 	log.message.format.version = 2.4-IV1
[36mkafka_1          |[0m 	log.message.timestamp.difference.max.ms = 9223372036854775807
[36mkafka_1          |[0m 	log.message.timestamp.type = CreateTime
[36mkafka_1          |[0m 	log.preallocate = false
[36mkafka_1          |[0m 	log.retention.bytes = -1
[36mkafka_1          |[0m 	log.retention.check.interval.ms = 300000
[36mkafka_1          |[0m 	log.retention.hours = 168
[36mkafka_1          |[0m 	log.retention.minutes = null
[36mkafka_1          |[0m 	log.retention.ms = null
[36mkafka_1          |[0m 	log.roll.hours = 168
[36mkafka_1          |[0m 	log.roll.jitter.hours = 0
[36mkafka_1          |[0m 	log.roll.jitter.ms = null
[36mkafka_1          |[0m 	log.roll.ms = null
[36mkafka_1          |[0m 	log.segment.bytes = 1073741824
[36mkafka_1          |[0m 	log.segment.delete.delay.ms = 60000
[36mkafka_1          |[0m 	max.connections = 2147483647
[36mkafka_1          |[0m 	max.connections.per.ip = 2147483647
[36mkafka_1          |[0m 	max.connections.per.ip.overrides = 
[36mkafka_1          |[0m 	max.incremental.fetch.session.cache.slots = 1000
[36mkafka_1          |[0m 	message.max.bytes = 1000012
[36mkafka_1          |[0m 	metric.reporters = []
[36mkafka_1          |[0m 	metrics.num.samples = 2
[36mkafka_1          |[0m 	metrics.recording.level = INFO
[36mkafka_1          |[0m 	metrics.sample.window.ms = 30000
[36mkafka_1          |[0m 	min.insync.replicas = 1
[36mkafka_1          |[0m 	num.io.threads = 8
[36mkafka_1          |[0m 	num.network.threads = 3
[36mkafka_1          |[0m 	num.partitions = 1
[36mkafka_1          |[0m 	num.recovery.threads.per.data.dir = 1
[36mkafka_1          |[0m 	num.replica.alter.log.dirs.threads = null
[36mkafka_1          |[0m 	num.replica.fetchers = 1
[36mkafka_1          |[0m 	offset.metadata.max.bytes = 4096
[36mkafka_1          |[0m 	offsets.commit.required.acks = -1
[36mkafka_1          |[0m 	offsets.commit.timeout.ms = 5000
[36mkafka_1          |[0m 	offsets.load.buffer.size = 5242880
[36mkafka_1          |[0m 	offsets.retention.check.interval.ms = 600000
[36mkafka_1          |[0m 	offsets.retention.minutes = 10080
[36mkafka_1          |[0m 	offsets.topic.compression.codec = 0
[36mkafka_1          |[0m 	offsets.topic.num.partitions = 50
[36mkafka_1          |[0m 	offsets.topic.replication.factor = 1
[36mkafka_1          |[0m 	offsets.topic.segment.bytes = 104857600
[36mkafka_1          |[0m 	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
[36mkafka_1          |[0m 	password.encoder.iterations = 4096
[36mkafka_1          |[0m 	password.encoder.key.length = 128
[36mkafka_1          |[0m 	password.encoder.keyfactory.algorithm = null
[36mkafka_1          |[0m 	password.encoder.old.secret = null
[36mkafka_1          |[0m 	password.encoder.secret = null
[36mkafka_1          |[0m 	port = 9092
[36mkafka_1          |[0m 	principal.builder.class = null
[36mkafka_1          |[0m 	producer.purgatory.purge.interval.requests = 1000
[36mkafka_1          |[0m 	queued.max.request.bytes = -1
[36mkafka_1          |[0m 	queued.max.requests = 500
[36mkafka_1          |[0m 	quota.consumer.default = 9223372036854775807
[36mkafka_1          |[0m 	quota.producer.default = 9223372036854775807
[36mkafka_1          |[0m 	quota.window.num = 11
[36mkafka_1          |[0m 	quota.window.size.seconds = 1
[36mkafka_1          |[0m 	replica.fetch.backoff.ms = 1000
[36mkafka_1          |[0m 	replica.fetch.max.bytes = 1048576
[36mkafka_1          |[0m 	replica.fetch.min.bytes = 1
[36mkafka_1          |[0m 	replica.fetch.response.max.bytes = 10485760
[36mkafka_1          |[0m 	replica.fetch.wait.max.ms = 500
[36mkafka_1          |[0m 	replica.high.watermark.checkpoint.interval.ms = 5000
[36mkafka_1          |[0m 	replica.lag.time.max.ms = 10000
[36mkafka_1          |[0m 	replica.selector.class = null
[36mkafka_1          |[0m 	replica.socket.receive.buffer.bytes = 65536
[36mkafka_1          |[0m 	replica.socket.timeout.ms = 30000
[36mkafka_1          |[0m 	replication.quota.window.num = 11
[36mkafka_1          |[0m 	replication.quota.window.size.seconds = 1
[36mkafka_1          |[0m 	request.timeout.ms = 30000
[36mkafka_1          |[0m 	reserved.broker.max.id = 1000
[36mkafka_1          |[0m 	sasl.client.callback.handler.class = null
[36mkafka_1          |[0m 	sasl.enabled.mechanisms = [GSSAPI]
[36mkafka_1          |[0m 	sasl.jaas.config = null
[36mkafka_1          |[0m 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
[36mkafka_1          |[0m 	sasl.kerberos.min.time.before.relogin = 60000
[36mkafka_1          |[0m 	sasl.kerberos.principal.to.local.rules = [DEFAULT]
[36mkafka_1          |[0m 	sasl.kerberos.service.name = null
[36mkafka_1          |[0m 	sasl.kerberos.ticket.renew.jitter = 0.05
[36mkafka_1          |[0m 	sasl.kerberos.ticket.renew.window.factor = 0.8
[36mkafka_1          |[0m 	sasl.login.callback.handler.class = null
[36mkafka_1          |[0m 	sasl.login.class = null
[36mkafka_1          |[0m 	sasl.login.refresh.buffer.seconds = 300
[36mkafka_1          |[0m 	sasl.login.refresh.min.period.seconds = 60
[36mkafka_1          |[0m 	sasl.login.refresh.window.factor = 0.8
[36mkafka_1          |[0m 	sasl.login.refresh.window.jitter = 0.05
[36mkafka_1          |[0m 	sasl.mechanism.inter.broker.protocol = GSSAPI
[36mkafka_1          |[0m 	sasl.server.callback.handler.class = null
[36mkafka_1          |[0m 	security.inter.broker.protocol = PLAINTEXT
[36mkafka_1          |[0m 	security.providers = null
[36mkafka_1          |[0m 	socket.receive.buffer.bytes = 102400
[36mkafka_1          |[0m 	socket.request.max.bytes = 104857600
[36mkafka_1          |[0m 	socket.send.buffer.bytes = 102400
[36mkafka_1          |[0m 	ssl.cipher.suites = []
[36mkafka_1          |[0m 	ssl.client.auth = none
[36mkafka_1          |[0m 	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
[36mkafka_1          |[0m 	ssl.endpoint.identification.algorithm = https
[36mkafka_1          |[0m 	ssl.key.password = null
[36mkafka_1          |[0m 	ssl.keymanager.algorithm = SunX509
[36mkafka_1          |[0m 	ssl.keystore.location = null
[36mkafka_1          |[0m 	ssl.keystore.password = null
[36mkafka_1          |[0m 	ssl.keystore.type = JKS
[36mkafka_1          |[0m 	ssl.principal.mapping.rules = DEFAULT
[36mkafka_1          |[0m 	ssl.protocol = TLS
[36mkafka_1          |[0m 	ssl.provider = null
[36mkafka_1          |[0m 	ssl.secure.random.implementation = null
[36mkafka_1          |[0m 	ssl.trustmanager.algorithm = PKIX
[36mkafka_1          |[0m 	ssl.truststore.location = null
[36mkafka_1          |[0m 	ssl.truststore.password = null
[36mkafka_1          |[0m 	ssl.truststore.type = JKS
[36mkafka_1          |[0m 	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
[36mkafka_1          |[0m 	transaction.max.timeout.ms = 900000
[36mkafka_1          |[0m 	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
[36mkafka_1          |[0m 	transaction.state.log.load.buffer.size = 5242880
[36mkafka_1          |[0m 	transaction.state.log.min.isr = 1
[36mkafka_1          |[0m 	transaction.state.log.num.partitions = 50
[36mkafka_1          |[0m 	transaction.state.log.replication.factor = 1
[36mkafka_1          |[0m 	transaction.state.log.segment.bytes = 104857600
[36mkafka_1          |[0m 	transactional.id.expiration.ms = 604800000
[36mkafka_1          |[0m 	unclean.leader.election.enable = false
[36mkafka_1          |[0m 	zookeeper.connect = zookeeper:2181
[36mkafka_1          |[0m 	zookeeper.connection.timeout.ms = 6000
[36mkafka_1          |[0m 	zookeeper.max.in.flight.requests = 10
[36mkafka_1          |[0m 	zookeeper.session.timeout.ms = 6000
[36mkafka_1          |[0m 	zookeeper.set.acl = false
[36mkafka_1          |[0m 	zookeeper.sync.time.ms = 2000
[36mkafka_1          |[0m  (kafka.server.KafkaConfig)
[36mkafka_1          |[0m [2020-04-13 18:15:33,419] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,419] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,419] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,872 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
[36mkafka_1          |[0m [2020-04-13 18:15:33,442] INFO Log directory /kafka/kafka-logs-bfe30d3c8c3c not found, creating it. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:33,448] INFO Loading logs. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:33,454] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,872 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.13
[36mkafka_1          |[0m [2020-04-13 18:15:33,466] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:33,469] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,874 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,874 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,874 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,882 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:31,886 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:32,908 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /192.168.80.3:43778
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:32,912 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /192.168.80.3:43778
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:32,914 [myid:] - INFO  [SyncThread:0:FileTxnLog@213] - Creating new log file: log.1
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:32,933 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100004f727c0000 with negotiated timeout 6000 for client /192.168.80.3:43778
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:33,028 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:create cxid:0x2 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:33,043 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:create cxid:0x6 zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:33,063 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:create cxid:0x9 zxid:0xa txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:33,281 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:create cxid:0x15 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[36mkafka_1          |[0m [2020-04-13 18:15:33,867] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[36mkafka_1          |[0m [2020-04-13 18:15:33,895] INFO [SocketServer brokerId=1001] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[36mkafka_1          |[0m [2020-04-13 18:15:33,897] INFO [SocketServer brokerId=1001] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[36mkafka_1          |[0m [2020-04-13 18:15:33,915] INFO [ExpirationReaper-1001-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,917] INFO [ExpirationReaper-1001-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,917] INFO [ExpirationReaper-1001-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,918] INFO [ExpirationReaper-1001-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:33,930] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[36mkafka_1          |[0m [2020-04-13 18:15:33,951] INFO Creating /brokers/ids/1001 (is it secure? false) (kafka.zk.KafkaZkClient)
[36mkafka_1          |[0m [2020-04-13 18:15:33,971] INFO Stat of the created znode at /brokers/ids/1001 is: 25,25,1586801733961,1586801733961,1,0,0,72057935261073408,180,0,25
[36mkafka_1          |[0m  (kafka.zk.KafkaZkClient)
[36mkafka_1          |[0m [2020-04-13 18:15:33,971] INFO Registered broker 1001 at path /brokers/ids/1001 with addresses: ArrayBuffer(EndPoint(kafka,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 25 (kafka.zk.KafkaZkClient)
[36mkafka_1          |[0m [2020-04-13 18:15:34,035] INFO [ExpirationReaper-1001-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:34,037] INFO [ExpirationReaper-1001-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:34,038] INFO [ExpirationReaper-1001-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:34,052] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[36mkafka_1          |[0m [2020-04-13 18:15:34,071] INFO [GroupCoordinator 1001]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[36mkafka_1          |[0m [2020-04-13 18:15:34,072] INFO [GroupCoordinator 1001]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[36mkafka_1          |[0m [2020-04-13 18:15:34,077] INFO [GroupMetadataManager brokerId=1001] Removed 0 expired offsets in 5 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:34,084] INFO [ProducerId Manager 1001]: Acquired new producerId block (brokerId:1001,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[36mkafka_1          |[0m [2020-04-13 18:15:34,105] INFO [TransactionCoordinator id=1001] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[36mkafka_1          |[0m [2020-04-13 18:15:34,106] INFO [Transaction Marker Channel Manager 1001]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[36mkafka_1          |[0m [2020-04-13 18:15:34,106] INFO [TransactionCoordinator id=1001] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[36mkafka_1          |[0m [2020-04-13 18:15:34,134] INFO [ExpirationReaper-1001-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[36mkafka_1          |[0m [2020-04-13 18:15:34,151] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:34,155 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@596] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:multi cxid:0x34 zxid:0x1d txntype:-1 reqpath:n/a aborting remaining multi ops. Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
[36mkafka_1          |[0m [2020-04-13 18:15:34,169] INFO [SocketServer brokerId=1001] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[36mkafka_1          |[0m [2020-04-13 18:15:34,173] INFO Kafka version: 2.4.1 (org.apache.kafka.common.utils.AppInfoParser)
[36mkafka_1          |[0m [2020-04-13 18:15:34,173] INFO Kafka commitId: c57222ae8cd7866b (org.apache.kafka.common.utils.AppInfoParser)
[36mkafka_1          |[0m [2020-04-13 18:15:34,173] INFO Kafka startTimeMs: 1586801734169 (org.apache.kafka.common.utils.AppInfoParser)
[36mkafka_1          |[0m [2020-04-13 18:15:34,175] INFO [KafkaServer id=1001] started (kafka.server.KafkaServer)
[35mnode2_1          |[0m %7|1586801734.221|CONNECT|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: Selected for cluster connection: coordinator query (broker has 2 connection attempt(s))
[35mnode2_1          |[0m %7|1586801734.221|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": no broker available for coordinator query: intervaled in state query-coord
[35mnode2_1          |[0m %7|1586801734.221|CONNECT|rdkafka#consumer-1| [thrd:main]: Not selecting any broker for cluster connection: still suppressed for 49ms: no cluster connection
[35mnode2_1          |[0m %7|1586801734.221|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Received CONNECT op
[35mnode2_1          |[0m %7|1586801734.221|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state INIT -> TRY_CONNECT
[35mnode2_1          |[0m %7|1586801734.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: broker in state TRY_CONNECT connecting
[35mnode2_1          |[0m %7|1586801734.222|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state TRY_CONNECT -> CONNECT
[35mnode2_1          |[0m %7|1586801734.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connecting to ipv4#192.168.80.3:9092 (plaintext) with socket 10
[35mnode2_1          |[0m %7|1586801734.222|CONNECT|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connected to ipv4#192.168.80.3:9092
[35mnode2_1          |[0m %7|1586801734.222|CONNECTED|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Connected (#1)
[35mnode2_1          |[0m %7|1586801734.222|FEATURE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Updated enabled protocol features +ApiVersion to ApiVersion
[35mnode2_1          |[0m %7|1586801734.222|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state CONNECT -> APIVERSION_QUERY
[35mnode2_1          |[0m %7|1586801734.222|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.222|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Sent ApiVersionRequest (v3, 62 bytes @ 0, CorrId 1)
[35mnode2_1          |[0m %7|1586801734.274|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Received ApiVersionResponse (v3, 344 bytes, CorrId 1, rtt 51.97ms)
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker API support:
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Produce (0) Versions 0..8
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Fetch (1) Versions 0..11
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Offset (2) Versions 0..5
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Metadata (3) Versions 0..9
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey LeaderAndIsr (4) Versions 0..4
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey StopReplica (5) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey UpdateMetadata (6) Versions 0..6
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey ControlledShutdown (7) Versions 0..3
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey OffsetCommit (8) Versions 0..8
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey OffsetFetch (9) Versions 0..6
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey FindCoordinator (10) Versions 0..3
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey JoinGroup (11) Versions 0..6
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Heartbeat (12) Versions 0..4
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey LeaveGroup (13) Versions 0..4
[35mnode2_1          |[0m %7|1586801734.274|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey SyncGroup (14) Versions 0..4
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DescribeGroups (15) Versions 0..5
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey ListGroups (16) Versions 0..3
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey SaslHandshake (17) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey ApiVersion (18) Versions 0..3
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey CreateTopics (19) Versions 0..5
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DeleteTopics (20) Versions 0..4
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DeleteRecords (21) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey InitProducerId (22) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey OffsetForLeaderEpoch (23) Versions 0..3
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey AddPartitionsToTxn (24) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey AddOffsetsToTxn (25) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey EndTxn (26) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey WriteTxnMarkers (27) Versions 0..0
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey TxnOffsetCommit (28) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DescribeAcls (29) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey CreateAcls (30) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DeleteAcls (31) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DescribeConfigs (32) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey AlterConfigs (33) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey AlterReplicaLogDirs (34) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DescribeLogDirs (35) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey SaslAuthenticate (36) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey CreatePartitions (37) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey CreateDelegationToken (38) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey RenewDelegationToken (39) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey ExpireDelegationToken (40) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DescribeDelegationToken (41) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey DeleteGroups (42) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Unknown-43? (43) Versions 0..2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Unknown-44? (44) Versions 0..1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Unknown-45? (45) Versions 0..0
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Unknown-46? (46) Versions 0..0
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:   ApiKey Unknown-47? (47) Versions 0..0
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature MsgVer1: Produce (2..2) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature MsgVer1: Fetch (2..2) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature MsgVer1
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature MsgVer2: Produce (3..3) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature MsgVer2: Fetch (4..4) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature MsgVer2
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature ApiVersion: ApiVersion (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature ApiVersion
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerGroupCoordinator: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature BrokerGroupCoordinator
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: OffsetCommit (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: OffsetFetch (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: JoinGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: SyncGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: Heartbeat (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature BrokerBalancedConsumer: LeaveGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature BrokerBalancedConsumer
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature ThrottleTime: Produce (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature ThrottleTime: Fetch (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature ThrottleTime
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature Sasl: JoinGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature Sasl
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature SaslHandshake: SaslHandshake (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature SaslHandshake
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature LZ4: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature LZ4
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature OffsetTime: Offset (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature OffsetTime
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature IdempotentProducer: InitProducerId (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature IdempotentProducer
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature ZSTD: Produce (7..7) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature ZSTD: Fetch (10..10) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature ZSTD
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature SaslAuthReq: SaslHandshake (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap:  Feature SaslAuthReq: SaslAuthenticate (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801734.275|APIVERSION|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Enabling feature SaslAuthReq
[35mnode2_1          |[0m %7|1586801734.275|FEATURE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Updated enabled protocol features to MsgVer1,ApiVersion,BrokerBalancedConsumer,ThrottleTime,Sasl,SaslHandshake,BrokerGroupCoordinator,LZ4,OffsetTime,MsgVer2,IdempotentProducer,ZSTD,SaslAuthReq
[35mnode2_1          |[0m %7|1586801734.275|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Broker changed state APIVERSION_QUERY -> UP
[35mnode2_1          |[0m %7|1586801734.275|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.275|METADATA|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Request metadata for brokers only: connected
[35mnode2_1          |[0m %7|1586801734.275|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Sent MetadataRequest (v2, 25 bytes @ 0, CorrId 2)
[35mnode2_1          |[0m %7|1586801734.293|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: Received MetadataResponse (v2, 53 bytes, CorrId 2, rtt 18.08ms)
[35mnode2_1          |[0m %7|1586801734.293|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: ===== Received metadata: connected =====
[35mnode2_1          |[0m %7|1586801734.293|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: ClusterId: JDtSBRIhRFipFkhscA09EQ, ControllerId: 1001
[35mnode2_1          |[0m %7|1586801734.293|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: 1 brokers, 0 topics
[35mnode2_1          |[0m %7|1586801734.293|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap:   Broker #0/1: kafka:9092 NodeId 1001
[35mnode2_1          |[0m %7|1586801734.293|CLUSTERID|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: ClusterId update "" -> "JDtSBRIhRFipFkhscA09EQ"
[35mnode2_1          |[0m %7|1586801734.293|CONTROLLERID|rdkafka#consumer-1| [thrd:main]: kafka:9092/bootstrap: ControllerId update -1 -> 1001
[35mnode2_1          |[0m %7|1586801734.293|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.293|UPDATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/bootstrap: NodeId changed from -1 to 1001
[35mnode2_1          |[0m %7|1586801734.293|UPDATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Name changed from kafka:9092/bootstrap to kafka:9092/1001
[35mnode2_1          |[0m %7|1586801734.293|LEADER|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Mapped 0 partition(s) to broker
[35mnode2_1          |[0m %7|1586801734.293|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Broker changed state UP -> UPDATE
[35mnode2_1          |[0m %7|1586801734.293|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.293|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801734.293|STATE|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Broker changed state UPDATE -> UP
[35mnode2_1          |[0m %7|1586801734.293|BROADCAST|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: Broadcasting state change
[36mkafka_1          |[0m [2020-04-13 18:15:34,309] INFO Creating topic striot-queue with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:34,311 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:setData cxid:0x3f zxid:0x1e txntype:-1 reqpath:n/a Error Path:/config/topics/striot-queue Error:KeeperErrorCode = NoNode for /config/topics/striot-queue
[36mkafka_1          |[0m [2020-04-13 18:15:34,331] INFO [KafkaApi-1001] Auto creation of topic striot-queue with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[36mkafka_1          |[0m [2020-04-13 18:15:34,406] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(striot-queue-0) (kafka.server.ReplicaFetcherManager)
[36mkafka_1          |[0m [2020-04-13 18:15:34,484] INFO [Log partition=striot-queue-0, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:34,489] INFO [Log partition=striot-queue-0, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 40 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:34,491] INFO Created log for partition striot-queue-0 in /kafka/kafka-logs-bfe30d3c8c3c/striot-queue-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:34,492] INFO [Partition striot-queue-0 broker=1001] No checkpointed highwatermark is found for partition striot-queue-0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:34,493] INFO [Partition striot-queue-0 broker=1001] Log loaded for partition striot-queue-0 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:34,493] INFO [Partition striot-queue-0 broker=1001] striot-queue-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[35mnode2_1          |[0m %7|1586801735.221|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group": querying for coordinator: intervaled in state query-coord
[35mnode2_1          |[0m %7|1586801735.221|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state query-coord -> wait-coord (v1, join-state init)
[35mnode2_1          |[0m %7|1586801735.221|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801735.222|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Sent FindCoordinatorRequest (v2, 40 bytes @ 0, CorrId 3)
[36mkafka_1          |[0m [2020-04-13 18:15:35,245] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(1001), 32 -> ArrayBuffer(1001), 41 -> ArrayBuffer(1001), 17 -> ArrayBuffer(1001), 8 -> ArrayBuffer(1001), 35 -> ArrayBuffer(1001), 44 -> ArrayBuffer(1001), 26 -> ArrayBuffer(1001), 11 -> ArrayBuffer(1001), 29 -> ArrayBuffer(1001), 38 -> ArrayBuffer(1001), 47 -> ArrayBuffer(1001), 20 -> ArrayBuffer(1001), 2 -> ArrayBuffer(1001), 5 -> ArrayBuffer(1001), 14 -> ArrayBuffer(1001), 46 -> ArrayBuffer(1001), 49 -> ArrayBuffer(1001), 40 -> ArrayBuffer(1001), 13 -> ArrayBuffer(1001), 4 -> ArrayBuffer(1001), 22 -> ArrayBuffer(1001), 31 -> ArrayBuffer(1001), 16 -> ArrayBuffer(1001), 7 -> ArrayBuffer(1001), 43 -> ArrayBuffer(1001), 25 -> ArrayBuffer(1001), 34 -> ArrayBuffer(1001), 10 -> ArrayBuffer(1001), 37 -> ArrayBuffer(1001), 1 -> ArrayBuffer(1001), 19 -> ArrayBuffer(1001), 28 -> ArrayBuffer(1001), 45 -> ArrayBuffer(1001), 27 -> ArrayBuffer(1001), 36 -> ArrayBuffer(1001), 18 -> ArrayBuffer(1001), 9 -> ArrayBuffer(1001), 21 -> ArrayBuffer(1001), 48 -> ArrayBuffer(1001), 3 -> ArrayBuffer(1001), 12 -> ArrayBuffer(1001), 30 -> ArrayBuffer(1001), 39 -> ArrayBuffer(1001), 15 -> ArrayBuffer(1001), 42 -> ArrayBuffer(1001), 24 -> ArrayBuffer(1001), 6 -> ArrayBuffer(1001), 33 -> ArrayBuffer(1001), 0 -> ArrayBuffer(1001)) (kafka.zk.AdminZkClient)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:35,247 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100004f727c0000 type:setData cxid:0x4c zxid:0x24 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
[36mkafka_1          |[0m [2020-04-13 18:15:35,264] INFO [KafkaApi-1001] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[35mnode2_1          |[0m %7|1586801735.267|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Received FindCoordinatorResponse (v2, 51 bytes, CorrId 3, rtt 45.37ms)
[35mnode2_1          |[0m %7|1586801735.267|CGRPCOORD|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group" FindCoordinator response error: COORDINATOR_NOT_AVAILABLE: The coordinator is not available.
[35mnode2_1          |[0m %7|1586801735.267|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state wait-coord -> query-coord (v1, join-state init)
[35mnode2_1          |[0m %7|1586801735.267|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[36mkafka_1          |[0m [2020-04-13 18:15:35,498] INFO [ReplicaFetcherManager on broker 1001] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,503] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,504] INFO [Log partition=__consumer_offsets-0, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,505] INFO Created log for partition __consumer_offsets-0 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,505] INFO [Partition __consumer_offsets-0 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,505] INFO [Partition __consumer_offsets-0 broker=1001] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,506] INFO [Partition __consumer_offsets-0 broker=1001] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,515] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,515] INFO [Log partition=__consumer_offsets-29, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,516] INFO Created log for partition __consumer_offsets-29 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,516] INFO [Partition __consumer_offsets-29 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,516] INFO [Partition __consumer_offsets-29 broker=1001] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,516] INFO [Partition __consumer_offsets-29 broker=1001] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,525] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,525] INFO [Log partition=__consumer_offsets-48, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,526] INFO Created log for partition __consumer_offsets-48 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,526] INFO [Partition __consumer_offsets-48 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,526] INFO [Partition __consumer_offsets-48 broker=1001] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,526] INFO [Partition __consumer_offsets-48 broker=1001] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,535] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,535] INFO [Log partition=__consumer_offsets-10, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,536] INFO Created log for partition __consumer_offsets-10 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,536] INFO [Partition __consumer_offsets-10 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,536] INFO [Partition __consumer_offsets-10 broker=1001] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,536] INFO [Partition __consumer_offsets-10 broker=1001] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,546] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,547] INFO [Log partition=__consumer_offsets-45, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,548] INFO Created log for partition __consumer_offsets-45 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,548] INFO [Partition __consumer_offsets-45 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,548] INFO [Partition __consumer_offsets-45 broker=1001] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,548] INFO [Partition __consumer_offsets-45 broker=1001] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,562] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,562] INFO [Log partition=__consumer_offsets-26, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,563] INFO Created log for partition __consumer_offsets-26 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,563] INFO [Partition __consumer_offsets-26 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,563] INFO [Partition __consumer_offsets-26 broker=1001] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,563] INFO [Partition __consumer_offsets-26 broker=1001] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,578] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,579] INFO [Log partition=__consumer_offsets-7, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,580] INFO Created log for partition __consumer_offsets-7 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,580] INFO [Partition __consumer_offsets-7 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,580] INFO [Partition __consumer_offsets-7 broker=1001] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,580] INFO [Partition __consumer_offsets-7 broker=1001] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,588] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,589] INFO [Log partition=__consumer_offsets-42, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,589] INFO Created log for partition __consumer_offsets-42 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,589] INFO [Partition __consumer_offsets-42 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,589] INFO [Partition __consumer_offsets-42 broker=1001] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,589] INFO [Partition __consumer_offsets-42 broker=1001] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,598] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,598] INFO [Log partition=__consumer_offsets-4, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,599] INFO Created log for partition __consumer_offsets-4 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,599] INFO [Partition __consumer_offsets-4 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,599] INFO [Partition __consumer_offsets-4 broker=1001] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,599] INFO [Partition __consumer_offsets-4 broker=1001] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,609] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,609] INFO [Log partition=__consumer_offsets-23, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,610] INFO Created log for partition __consumer_offsets-23 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,611] INFO [Partition __consumer_offsets-23 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,611] INFO [Partition __consumer_offsets-23 broker=1001] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,611] INFO [Partition __consumer_offsets-23 broker=1001] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,619] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,619] INFO [Log partition=__consumer_offsets-1, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,620] INFO Created log for partition __consumer_offsets-1 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,620] INFO [Partition __consumer_offsets-1 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,620] INFO [Partition __consumer_offsets-1 broker=1001] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,620] INFO [Partition __consumer_offsets-1 broker=1001] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,628] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,628] INFO [Log partition=__consumer_offsets-20, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,629] INFO Created log for partition __consumer_offsets-20 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,629] INFO [Partition __consumer_offsets-20 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,629] INFO [Partition __consumer_offsets-20 broker=1001] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,630] INFO [Partition __consumer_offsets-20 broker=1001] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,645] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,645] INFO [Log partition=__consumer_offsets-39, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,646] INFO Created log for partition __consumer_offsets-39 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,646] INFO [Partition __consumer_offsets-39 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,646] INFO [Partition __consumer_offsets-39 broker=1001] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,646] INFO [Partition __consumer_offsets-39 broker=1001] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,656] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,656] INFO [Log partition=__consumer_offsets-17, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,657] INFO Created log for partition __consumer_offsets-17 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,657] INFO [Partition __consumer_offsets-17 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,657] INFO [Partition __consumer_offsets-17 broker=1001] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,657] INFO [Partition __consumer_offsets-17 broker=1001] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,665] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,665] INFO [Log partition=__consumer_offsets-36, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,666] INFO Created log for partition __consumer_offsets-36 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,666] INFO [Partition __consumer_offsets-36 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,666] INFO [Partition __consumer_offsets-36 broker=1001] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,666] INFO [Partition __consumer_offsets-36 broker=1001] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,676] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,677] INFO [Log partition=__consumer_offsets-14, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,677] INFO Created log for partition __consumer_offsets-14 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,677] INFO [Partition __consumer_offsets-14 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,678] INFO [Partition __consumer_offsets-14 broker=1001] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,678] INFO [Partition __consumer_offsets-14 broker=1001] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,692] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,693] INFO [Log partition=__consumer_offsets-33, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,693] INFO Created log for partition __consumer_offsets-33 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,693] INFO [Partition __consumer_offsets-33 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,693] INFO [Partition __consumer_offsets-33 broker=1001] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,693] INFO [Partition __consumer_offsets-33 broker=1001] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,709] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,709] INFO [Log partition=__consumer_offsets-49, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,710] INFO Created log for partition __consumer_offsets-49 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,710] INFO [Partition __consumer_offsets-49 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,711] INFO [Partition __consumer_offsets-49 broker=1001] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,711] INFO [Partition __consumer_offsets-49 broker=1001] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,726] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,727] INFO [Log partition=__consumer_offsets-11, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,728] INFO Created log for partition __consumer_offsets-11 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,728] INFO [Partition __consumer_offsets-11 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,728] INFO [Partition __consumer_offsets-11 broker=1001] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,728] INFO [Partition __consumer_offsets-11 broker=1001] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,739] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,740] INFO [Log partition=__consumer_offsets-30, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 4 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,741] INFO Created log for partition __consumer_offsets-30 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,741] INFO [Partition __consumer_offsets-30 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,741] INFO [Partition __consumer_offsets-30 broker=1001] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,741] INFO [Partition __consumer_offsets-30 broker=1001] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,750] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,750] INFO [Log partition=__consumer_offsets-46, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,751] INFO Created log for partition __consumer_offsets-46 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,751] INFO [Partition __consumer_offsets-46 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,751] INFO [Partition __consumer_offsets-46 broker=1001] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,751] INFO [Partition __consumer_offsets-46 broker=1001] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,763] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,764] INFO [Log partition=__consumer_offsets-27, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,765] INFO Created log for partition __consumer_offsets-27 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,765] INFO [Partition __consumer_offsets-27 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,765] INFO [Partition __consumer_offsets-27 broker=1001] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,765] INFO [Partition __consumer_offsets-27 broker=1001] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,775] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,775] INFO [Log partition=__consumer_offsets-8, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,776] INFO Created log for partition __consumer_offsets-8 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,776] INFO [Partition __consumer_offsets-8 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,776] INFO [Partition __consumer_offsets-8 broker=1001] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,777] INFO [Partition __consumer_offsets-8 broker=1001] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,787] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,788] INFO [Log partition=__consumer_offsets-24, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,789] INFO Created log for partition __consumer_offsets-24 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,789] INFO [Partition __consumer_offsets-24 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,789] INFO [Partition __consumer_offsets-24 broker=1001] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,789] INFO [Partition __consumer_offsets-24 broker=1001] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,801] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,802] INFO [Log partition=__consumer_offsets-43, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,803] INFO Created log for partition __consumer_offsets-43 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,803] INFO [Partition __consumer_offsets-43 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,803] INFO [Partition __consumer_offsets-43 broker=1001] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,803] INFO [Partition __consumer_offsets-43 broker=1001] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,812] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,813] INFO [Log partition=__consumer_offsets-5, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,813] INFO Created log for partition __consumer_offsets-5 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,813] INFO [Partition __consumer_offsets-5 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,814] INFO [Partition __consumer_offsets-5 broker=1001] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,814] INFO [Partition __consumer_offsets-5 broker=1001] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,822] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,822] INFO [Log partition=__consumer_offsets-21, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,823] INFO Created log for partition __consumer_offsets-21 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,823] INFO [Partition __consumer_offsets-21 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,823] INFO [Partition __consumer_offsets-21 broker=1001] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,823] INFO [Partition __consumer_offsets-21 broker=1001] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,838] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,838] INFO [Log partition=__consumer_offsets-40, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,839] INFO Created log for partition __consumer_offsets-40 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,839] INFO [Partition __consumer_offsets-40 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,839] INFO [Partition __consumer_offsets-40 broker=1001] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,839] INFO [Partition __consumer_offsets-40 broker=1001] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,848] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,849] INFO [Log partition=__consumer_offsets-2, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,849] INFO Created log for partition __consumer_offsets-2 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,849] INFO [Partition __consumer_offsets-2 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,849] INFO [Partition __consumer_offsets-2 broker=1001] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,849] INFO [Partition __consumer_offsets-2 broker=1001] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,858] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,858] INFO [Log partition=__consumer_offsets-37, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,859] INFO Created log for partition __consumer_offsets-37 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,859] INFO [Partition __consumer_offsets-37 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,859] INFO [Partition __consumer_offsets-37 broker=1001] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,859] INFO [Partition __consumer_offsets-37 broker=1001] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,874] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,875] INFO [Log partition=__consumer_offsets-18, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,876] INFO Created log for partition __consumer_offsets-18 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,876] INFO [Partition __consumer_offsets-18 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,876] INFO [Partition __consumer_offsets-18 broker=1001] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,876] INFO [Partition __consumer_offsets-18 broker=1001] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,885] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,886] INFO [Log partition=__consumer_offsets-34, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,886] INFO Created log for partition __consumer_offsets-34 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,886] INFO [Partition __consumer_offsets-34 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,886] INFO [Partition __consumer_offsets-34 broker=1001] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,886] INFO [Partition __consumer_offsets-34 broker=1001] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,894] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,895] INFO [Log partition=__consumer_offsets-15, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,895] INFO Created log for partition __consumer_offsets-15 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,895] INFO [Partition __consumer_offsets-15 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,896] INFO [Partition __consumer_offsets-15 broker=1001] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,896] INFO [Partition __consumer_offsets-15 broker=1001] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,904] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,905] INFO [Log partition=__consumer_offsets-12, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,905] INFO Created log for partition __consumer_offsets-12 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,905] INFO [Partition __consumer_offsets-12 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,905] INFO [Partition __consumer_offsets-12 broker=1001] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,905] INFO [Partition __consumer_offsets-12 broker=1001] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,913] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,914] INFO [Log partition=__consumer_offsets-31, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,915] INFO Created log for partition __consumer_offsets-31 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,915] INFO [Partition __consumer_offsets-31 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,915] INFO [Partition __consumer_offsets-31 broker=1001] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,915] INFO [Partition __consumer_offsets-31 broker=1001] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,923] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,923] INFO [Log partition=__consumer_offsets-9, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,924] INFO Created log for partition __consumer_offsets-9 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,924] INFO [Partition __consumer_offsets-9 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,924] INFO [Partition __consumer_offsets-9 broker=1001] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,924] INFO [Partition __consumer_offsets-9 broker=1001] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,941] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,941] INFO [Log partition=__consumer_offsets-47, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,942] INFO Created log for partition __consumer_offsets-47 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,943] INFO [Partition __consumer_offsets-47 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,943] INFO [Partition __consumer_offsets-47 broker=1001] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,943] INFO [Partition __consumer_offsets-47 broker=1001] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,951] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,952] INFO [Log partition=__consumer_offsets-19, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,953] INFO Created log for partition __consumer_offsets-19 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,953] INFO [Partition __consumer_offsets-19 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,953] INFO [Partition __consumer_offsets-19 broker=1001] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,953] INFO [Partition __consumer_offsets-19 broker=1001] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,967] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,967] INFO [Log partition=__consumer_offsets-28, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,968] INFO Created log for partition __consumer_offsets-28 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,968] INFO [Partition __consumer_offsets-28 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,968] INFO [Partition __consumer_offsets-28 broker=1001] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,968] INFO [Partition __consumer_offsets-28 broker=1001] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,976] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,977] INFO [Log partition=__consumer_offsets-38, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,977] INFO Created log for partition __consumer_offsets-38 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,978] INFO [Partition __consumer_offsets-38 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,978] INFO [Partition __consumer_offsets-38 broker=1001] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,978] INFO [Partition __consumer_offsets-38 broker=1001] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,986] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,986] INFO [Log partition=__consumer_offsets-35, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,987] INFO Created log for partition __consumer_offsets-35 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,987] INFO [Partition __consumer_offsets-35 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,987] INFO [Partition __consumer_offsets-35 broker=1001] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,987] INFO [Partition __consumer_offsets-35 broker=1001] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,995] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,996] INFO [Log partition=__consumer_offsets-6, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:35,997] INFO Created log for partition __consumer_offsets-6 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:35,997] INFO [Partition __consumer_offsets-6 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,997] INFO [Partition __consumer_offsets-6 broker=1001] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:35,997] INFO [Partition __consumer_offsets-6 broker=1001] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,006] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,006] INFO [Log partition=__consumer_offsets-44, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,007] INFO Created log for partition __consumer_offsets-44 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,007] INFO [Partition __consumer_offsets-44 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,007] INFO [Partition __consumer_offsets-44 broker=1001] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,007] INFO [Partition __consumer_offsets-44 broker=1001] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,016] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,016] INFO [Log partition=__consumer_offsets-25, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,017] INFO Created log for partition __consumer_offsets-25 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,017] INFO [Partition __consumer_offsets-25 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,017] INFO [Partition __consumer_offsets-25 broker=1001] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,017] INFO [Partition __consumer_offsets-25 broker=1001] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,026] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,026] INFO [Log partition=__consumer_offsets-16, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,027] INFO Created log for partition __consumer_offsets-16 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,027] INFO [Partition __consumer_offsets-16 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,027] INFO [Partition __consumer_offsets-16 broker=1001] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,027] INFO [Partition __consumer_offsets-16 broker=1001] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,035] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,035] INFO [Log partition=__consumer_offsets-22, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,036] INFO Created log for partition __consumer_offsets-22 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,036] INFO [Partition __consumer_offsets-22 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,036] INFO [Partition __consumer_offsets-22 broker=1001] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,036] INFO [Partition __consumer_offsets-22 broker=1001] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,044] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,044] INFO [Log partition=__consumer_offsets-41, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,046] INFO Created log for partition __consumer_offsets-41 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,046] INFO [Partition __consumer_offsets-41 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,046] INFO [Partition __consumer_offsets-41 broker=1001] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,046] INFO [Partition __consumer_offsets-41 broker=1001] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,054] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,055] INFO [Log partition=__consumer_offsets-32, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,055] INFO Created log for partition __consumer_offsets-32 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,055] INFO [Partition __consumer_offsets-32 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,055] INFO [Partition __consumer_offsets-32 broker=1001] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,055] INFO [Partition __consumer_offsets-32 broker=1001] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,064] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,064] INFO [Log partition=__consumer_offsets-3, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,065] INFO Created log for partition __consumer_offsets-3 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,065] INFO [Partition __consumer_offsets-3 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,066] INFO [Partition __consumer_offsets-3 broker=1001] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,066] INFO [Partition __consumer_offsets-3 broker=1001] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,079] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bfe30d3c8c3c] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,080] INFO [Log partition=__consumer_offsets-13, dir=/kafka/kafka-logs-bfe30d3c8c3c] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[36mkafka_1          |[0m [2020-04-13 18:15:36,080] INFO Created log for partition __consumer_offsets-13 in /kafka/kafka-logs-bfe30d3c8c3c/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,080] INFO [Partition __consumer_offsets-13 broker=1001] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,080] INFO [Partition __consumer_offsets-13 broker=1001] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,081] INFO [Partition __consumer_offsets-13 broker=1001] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[36mkafka_1          |[0m [2020-04-13 18:15:36,095] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,096] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,097] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,098] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,099] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,100] INFO [GroupMetadataManager brokerId=1001] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,105] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-22 in 8 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,105] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,106] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,106] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,107] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-34 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,107] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,107] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,108] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,108] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,109] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,109] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,109] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,110] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,110] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,111] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,112] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,112] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,113] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-19 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,113] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,113] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,114] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,114] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,115] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,115] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,115] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,116] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,116] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,116] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,116] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,117] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,117] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,117] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,117] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,118] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,118] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,118] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,118] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,119] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,119] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,119] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,119] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,119] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,120] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,120] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,120] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,120] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,120] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[36mkafka_1          |[0m [2020-04-13 18:15:36,121] INFO [GroupMetadataManager brokerId=1001] Finished loading offsets and group metadata from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[35mnode2_1          |[0m %7|1586801736.221|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group": querying for coordinator: intervaled in state query-coord
[35mnode2_1          |[0m %7|1586801736.221|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state query-coord -> wait-coord (v1, join-state init)
[35mnode2_1          |[0m %7|1586801736.221|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.221|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Sent FindCoordinatorRequest (v2, 40 bytes @ 0, CorrId 4)
[35mnode2_1          |[0m %7|1586801736.229|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Received FindCoordinatorResponse (v2, 27 bytes, CorrId 4, rtt 7.28ms)
[35mnode2_1          |[0m %7|1586801736.229|CGRPCOORD|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group" coordinator is kafka:9092 id 1001
[35mnode2_1          |[0m %7|1586801736.229|CGRPCOORD|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changing coordinator -1 -> 1001
[35mnode2_1          |[0m %7|1586801736.229|COORDSET|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" coordinator set to broker kafka:9092/1001
[35mnode2_1          |[0m %7|1586801736.229|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state wait-coord -> wait-broker-transport (v1, join-state init)
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.229|NODENAME|rdkafka#consumer-1| [thrd:main]: GroupCoordinator: Broker nodename changed from "" to "kafka:9092"
[35mnode2_1          |[0m %7|1586801736.229|CGRPQUERY|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group": querying for coordinator: intervaled in state wait-broker-transport
[35mnode2_1          |[0m %7|1586801736.229|CONNECT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Received CONNECT op
[35mnode2_1          |[0m %7|1586801736.229|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state INIT -> TRY_CONNECT
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.229|BROKERFAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: failed: err: Local: Broker transport failure: (errno: Success)
[35mnode2_1          |[0m %7|1586801736.229|FAIL|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Closing connection due to nodename change (after 0ms in state TRY_CONNECT)
[35mnode2_1          |[0m %7|1586801736.229|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state TRY_CONNECT -> DOWN
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.229|BUFQ|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801736.229|BUFQ|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Purging bufq with 0 buffers
[35mnode2_1          |[0m %7|1586801736.229|BUFQ|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Updating 0 buffers on connection reset
[35mnode2_1          |[0m %7|1586801736.229|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Sent FindCoordinatorRequest (v2, 40 bytes @ 0, CorrId 5)
[35mnode2_1          |[0m %7|1586801736.229|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state DOWN -> INIT
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.229|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state INIT -> TRY_CONNECT
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.229|CONNECT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: broker in state TRY_CONNECT connecting
[35mnode2_1          |[0m %7|1586801736.229|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state TRY_CONNECT -> CONNECT
[35mnode2_1          |[0m %7|1586801736.229|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.230|CONNECT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Connecting to ipv4#192.168.80.3:9092 (plaintext) with socket 11
[35mnode2_1          |[0m %7|1586801736.230|CONNECT|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Connected to ipv4#192.168.80.3:9092
[35mnode2_1          |[0m %7|1586801736.230|CONNECTED|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Connected (#1)
[35mnode2_1          |[0m %7|1586801736.230|FEATURE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Updated enabled protocol features +ApiVersion to ApiVersion
[35mnode2_1          |[0m %7|1586801736.230|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state CONNECT -> APIVERSION_QUERY
[35mnode2_1          |[0m %7|1586801736.230|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.230|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent ApiVersionRequest (v3, 62 bytes @ 0, CorrId 1)
[35mnode2_1          |[0m %7|1586801736.233|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received ApiVersionResponse (v3, 344 bytes, CorrId 1, rtt 2.47ms)
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Broker API support:
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Produce (0) Versions 0..8
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Fetch (1) Versions 0..11
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Offset (2) Versions 0..5
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Metadata (3) Versions 0..9
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey LeaderAndIsr (4) Versions 0..4
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey StopReplica (5) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey UpdateMetadata (6) Versions 0..6
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey ControlledShutdown (7) Versions 0..3
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey OffsetCommit (8) Versions 0..8
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey OffsetFetch (9) Versions 0..6
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey FindCoordinator (10) Versions 0..3
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey JoinGroup (11) Versions 0..6
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Heartbeat (12) Versions 0..4
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey LeaveGroup (13) Versions 0..4
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey SyncGroup (14) Versions 0..4
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DescribeGroups (15) Versions 0..5
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey ListGroups (16) Versions 0..3
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey SaslHandshake (17) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey ApiVersion (18) Versions 0..3
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey CreateTopics (19) Versions 0..5
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DeleteTopics (20) Versions 0..4
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DeleteRecords (21) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey InitProducerId (22) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey OffsetForLeaderEpoch (23) Versions 0..3
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey AddPartitionsToTxn (24) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey AddOffsetsToTxn (25) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey EndTxn (26) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey WriteTxnMarkers (27) Versions 0..0
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey TxnOffsetCommit (28) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DescribeAcls (29) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey CreateAcls (30) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DeleteAcls (31) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DescribeConfigs (32) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey AlterConfigs (33) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey AlterReplicaLogDirs (34) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DescribeLogDirs (35) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey SaslAuthenticate (36) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey CreatePartitions (37) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey CreateDelegationToken (38) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey RenewDelegationToken (39) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey ExpireDelegationToken (40) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DescribeDelegationToken (41) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey DeleteGroups (42) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Unknown-43? (43) Versions 0..2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Unknown-44? (44) Versions 0..1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Unknown-45? (45) Versions 0..0
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Unknown-46? (46) Versions 0..0
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:   ApiKey Unknown-47? (47) Versions 0..0
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature MsgVer1: Produce (2..2) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature MsgVer1: Fetch (2..2) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature MsgVer1
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature MsgVer2: Produce (3..3) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature MsgVer2: Fetch (4..4) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature MsgVer2
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature ApiVersion: ApiVersion (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature ApiVersion
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerGroupCoordinator: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature BrokerGroupCoordinator
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.233|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: OffsetCommit (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: OffsetFetch (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: JoinGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: SyncGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: Heartbeat (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature BrokerBalancedConsumer: LeaveGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature BrokerBalancedConsumer
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature ThrottleTime: Produce (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature ThrottleTime: Fetch (1..2) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature ThrottleTime
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature Sasl: JoinGroup (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature Sasl
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature SaslHandshake: SaslHandshake (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature SaslHandshake
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature LZ4: FindCoordinator (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature LZ4
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature OffsetTime: Offset (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature OffsetTime
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature IdempotentProducer: InitProducerId (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature IdempotentProducer
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature ZSTD: Produce (7..7) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature ZSTD: Fetch (10..10) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature ZSTD
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature SaslAuthReq: SaslHandshake (1..1) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001:  Feature SaslAuthReq: SaslAuthenticate (0..0) supported by broker
[35mnode2_1          |[0m %7|1586801736.234|APIVERSION|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Enabling feature SaslAuthReq
[35mnode2_1          |[0m %7|1586801736.234|FEATURE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Updated enabled protocol features to MsgVer1,ApiVersion,BrokerBalancedConsumer,ThrottleTime,Sasl,SaslHandshake,BrokerGroupCoordinator,LZ4,OffsetTime,MsgVer2,IdempotentProducer,ZSTD,SaslAuthReq
[35mnode2_1          |[0m %7|1586801736.234|STATE|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator: Broker changed state APIVERSION_QUERY -> UP
[35mnode2_1          |[0m %7|1586801736.234|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.234|METADATA|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Request metadata for brokers only: connected
[35mnode2_1          |[0m %7|1586801736.234|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent MetadataRequest (v2, 25 bytes @ 0, CorrId 2)
[35mnode2_1          |[0m %7|1586801736.234|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Received FindCoordinatorResponse (v2, 27 bytes, CorrId 5, rtt 5.05ms)
[35mnode2_1          |[0m %7|1586801736.234|CGRPCOORD|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Group "striot_con_group" coordinator is kafka:9092 id 1001
[35mnode2_1          |[0m %7|1586801736.234|CGRPSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed state wait-broker-transport -> up (v1, join-state init)
[35mnode2_1          |[0m %7|1586801736.234|BROADCAST|rdkafka#consumer-1| [thrd:main]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801736.234|JOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": join with 0 (1) subscribed topic(s)
[35mnode2_1          |[0m %7|1586801736.234|METADATA|rdkafka#consumer-1| [thrd:main]: Hinted cache of 1/1 topic(s) being queried
[35mnode2_1          |[0m %7|1586801736.234|CGRPMETADATA|rdkafka#consumer-1| [thrd:main]: consumer join: metadata for subscription only available for 0/1 topics (-1ms old)
[35mnode2_1          |[0m %7|1586801736.234|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Request metadata for 1 topic(s): consumer join
[35mnode2_1          |[0m %7|1586801736.234|JOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": postponing join until up-to-date metadata is available
[35mnode2_1          |[0m %7|1586801736.234|SEND|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Sent MetadataRequest (v2, 39 bytes @ 0, CorrId 6)
[35mnode2_1          |[0m %7|1586801736.235|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received MetadataResponse (v2, 53 bytes, CorrId 2, rtt 1.13ms)
[35mnode2_1          |[0m %7|1586801736.235|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: ===== Received metadata: connected =====
[35mnode2_1          |[0m %7|1586801736.235|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: ClusterId: JDtSBRIhRFipFkhscA09EQ, ControllerId: 1001
[35mnode2_1          |[0m %7|1586801736.235|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: 1 brokers, 0 topics
[35mnode2_1          |[0m %7|1586801736.235|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001:   Broker #0/1: kafka:9092 NodeId 1001
[35mnode2_1          |[0m %7|1586801736.236|RECV|rdkafka#consumer-1| [thrd:kafka:9092/bootstrap]: kafka:9092/1001: Received MetadataResponse (v2, 100 bytes, CorrId 6, rtt 1.33ms)
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: ===== Received metadata (for 1 requested topics): consumer join =====
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: ClusterId: JDtSBRIhRFipFkhscA09EQ, ControllerId: 1001
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: 1 brokers, 1 topics
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001:   Broker #0/1: kafka:9092 NodeId 1001
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001:   Topic #0/1: striot-queue with 1 partitions
[35mnode2_1          |[0m %7|1586801736.236|METADATA|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: 1/1 requested topic(s) seen in metadata
[35mnode2_1          |[0m %7|1586801736.236|SUBSCRIPTION|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": effective subscription list changed from 0 to 1 topic(s):
[35mnode2_1          |[0m %7|1586801736.236|SUBSCRIPTION|rdkafka#consumer-1| [thrd:main]:  Topic striot-queue with 1 partition(s)
[35mnode2_1          |[0m %7|1586801736.236|REJOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": subscription updated from metadata change: rejoining group
[35mnode2_1          |[0m %7|1586801736.236|GRPLEADER|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": resetting group leader info: Group rejoin
[35mnode2_1          |[0m %7|1586801736.236|REJOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" rejoining in join-state init without an assignment
[35mnode2_1          |[0m %7|1586801736.236|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" is rebalancing in state up (join-state init) without assignment: group rejoin
[35mnode2_1          |[0m %7|1586801736.236|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state init -> wait-unassign (v1, state up)
[35mnode2_1          |[0m %7|1586801736.236|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": unassign done in state up (join state wait-unassign): without new assignment: unassign (no previous assignment)
[35mnode2_1          |[0m %7|1586801736.236|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-unassign -> init (v1, state up)
[35mnode2_1          |[0m %7|1586801738.221|JOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": join with 1 (1) subscribed topic(s)
[35mnode2_1          |[0m %7|1586801738.221|CGRPMETADATA|rdkafka#consumer-1| [thrd:main]: consumer join: metadata for subscription is up to date (1984ms old)
[35mnode2_1          |[0m %7|1586801738.221|JOIN|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Joining group "striot_con_group" with 1 subscribed topic(s)
[35mnode2_1          |[0m %7|1586801738.221|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state init -> wait-join (v1, state up)
[35mnode2_1          |[0m %7|1586801738.221|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent JoinGroupRequest (v5, 140 bytes @ 0, CorrId 3)
[35mnode2_1          |[0m %7|1586801738.221|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[35mnode2_1          |[0m %7|1586801738.251|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received JoinGroupResponse (v5, 64 bytes, CorrId 3, rtt 30.17ms)
[35mnode2_1          |[0m %7|1586801738.251|JOINGROUP|rdkafka#consumer-1| [thrd:main]: JoinGroup response: GenerationId -1, Protocol , LeaderId , my MemberId rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9, 0 members in group: Broker: Group member needs a valid member ID
[35mnode2_1          |[0m %7|1586801738.251|REQERR|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: JoinGroupRequest failed: Broker: Group member needs a valid member ID: explicit actions Ignore
[35mnode2_1          |[0m %7|1586801738.251|MEMBERID|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": updating member id "" -> "rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9"
[35mnode2_1          |[0m %7|1586801738.251|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-join -> init (v1, state up)
[35mnode2_1          |[0m %7|1586801738.251|JOIN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": join with 1 (1) subscribed topic(s)
[35mnode2_1          |[0m %7|1586801738.251|CGRPMETADATA|rdkafka#consumer-1| [thrd:main]: consumer join: metadata for subscription is up to date (2015ms old)
[35mnode2_1          |[0m %7|1586801738.251|JOIN|rdkafka#consumer-1| [thrd:main]: kafka:9092/1001: Joining group "striot_con_group" with 1 subscribed topic(s)
[35mnode2_1          |[0m %7|1586801738.251|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state init -> wait-join (v1, state up)
[35mnode2_1          |[0m %7|1586801738.251|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent JoinGroupRequest (v5, 184 bytes @ 0, CorrId 4)
[35mnode2_1          |[0m %7|1586801738.251|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[36mkafka_1          |[0m [2020-04-13 18:15:38,261] INFO [GroupCoordinator 1001]: Preparing to rebalance group striot_con_group in state PreparingRebalance with old generation 0 (__consumer_offsets-20) (reason: Adding new member rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[36mkafka_1          |[0m [2020-04-13 18:15:38,270] INFO [GroupCoordinator 1001]: Stabilized group striot_con_group generation 1 (__consumer_offsets-20) (kafka.coordinator.group.GroupCoordinator)
[35mnode2_1          |[0m %7|1586801738.273|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received JoinGroupResponse (v5, 189 bytes, CorrId 4, rtt 21.79ms)
[35mnode2_1          |[0m %7|1586801738.273|JOINGROUP|rdkafka#consumer-1| [thrd:main]: JoinGroup response: GenerationId 1, Protocol range, LeaderId rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9 (me), my MemberId rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9, 1 members in group: (no error)
[35mnode2_1          |[0m %7|1586801738.273|JOINGROUP|rdkafka#consumer-1| [thrd:main]: Elected leader for group "striot_con_group" with 1 member(s)
[35mnode2_1          |[0m %7|1586801738.273|GRPLEADER|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": resetting group leader info: JoinGroup response clean-up
[35mnode2_1          |[0m %7|1586801738.273|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-join -> wait-metadata (v1, state up)
[35mnode2_1          |[0m %7|1586801738.273|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Request metadata for 1 topic(s): partition assignor
[35mnode2_1          |[0m %7|1586801738.273|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent MetadataRequest (v2, 39 bytes @ 0, CorrId 5)
[35mnode2_1          |[0m %7|1586801738.275|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received MetadataResponse (v2, 100 bytes, CorrId 5, rtt 1.81ms)
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: ===== Received metadata (for 1 requested topics): partition assignor =====
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: ClusterId: JDtSBRIhRFipFkhscA09EQ, ControllerId: 1001
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: 1 brokers, 1 topics
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001:   Broker #0/1: kafka:9092 NodeId 1001
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001:   Topic #0/1: striot-queue with 1 partitions
[35mnode2_1          |[0m %7|1586801738.275|METADATA|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: 1/1 requested topic(s) seen in metadata
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" running range assignment for 1 member(s):
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]:  Member "rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9" (me) with 1 subscription(s):
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]:   striot-queue [-1]
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]: range: Topic striot-queue with 1 partition(s) and 1 subscribing member(s)
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]: range: Member "rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9": assigned topic striot-queue partitions 0..0
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" range assignment for 1 member(s) finished in 0.039ms:
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]:  Member "rdkafka-dd7fb4ae-03c3-4cca-8c2f-10bb0fa95fb9" (me) assigned 1 partition(s):
[35mnode2_1          |[0m %7|1586801738.275|ASSIGN|rdkafka#consumer-1| [thrd:main]:   striot-queue [0]
[35mnode2_1          |[0m %7|1586801738.275|ASSIGNOR|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": "range" assignor run for 1 member(s)
[35mnode2_1          |[0m %7|1586801738.275|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-metadata -> wait-sync (v1, state up)
[35mnode2_1          |[0m %7|1586801738.276|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent SyncGroupRequest (v3, 177 bytes @ 0, CorrId 6)
[35mnode2_1          |[0m %7|1586801738.276|BROADCAST|rdkafka#consumer-1| [thrd:GroupCoordinator]: Broadcasting state change
[36mkafka_1          |[0m [2020-04-13 18:15:38,280] INFO [GroupCoordinator 1001]: Assignment received from leader for group striot_con_group for generation 1 (kafka.coordinator.group.GroupCoordinator)
[35mnode2_1          |[0m %7|1586801738.297|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received SyncGroupResponse (v3, 42 bytes, CorrId 6, rtt 21.95ms)
[35mnode2_1          |[0m %7|1586801738.298|SYNCGROUP|rdkafka#consumer-1| [thrd:main]: SyncGroup response: Success (32 bytes of MemberState data)
[35mnode2_1          |[0m %7|1586801738.298|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group": delegating assign of 1 partition(s) to application rebalance callback on queue rd_kafka_cgrp_new: new assignment
[35mnode2_1          |[0m %7|1586801738.298|CGRPJOINSTATE|rdkafka#consumer-1| [thrd:main]: Group "striot_con_group" changed join state wait-sync -> wait-assign-rebalance_cb (v1, state up)
[35mnode2_1          |[0m %7|1586801738.298|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801738.298|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 7)
[35mnode2_1          |[0m %7|1586801738.303|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 7, rtt 5.38ms)
[36mkafka_1          |[0m creating topics: striot-queue:1:1
[35mnode2_1          |[0m %7|1586801742.221|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801742.221|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 8)
[35mnode2_1          |[0m %7|1586801742.223|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 8, rtt 2.16ms)
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:42,781 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@215] - Accepted socket connection from /192.168.80.3:43792
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:42,784 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /192.168.80.3:43792
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:42,789 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100004f727c0001 with negotiated timeout 30000 for client /192.168.80.3:43792
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:42,993 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100004f727c0001
[36;1mzookeeper_1      |[0m 2020-04-13 18:15:42,998 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /192.168.80.3:43792 which had sessionid 0x100004f727c0001
[35mnode2_1          |[0m %7|1586801745.221|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801745.221|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 9)
[35mnode2_1          |[0m %7|1586801745.222|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 9, rtt 1.40ms)
[35mnode2_1          |[0m %7|1586801748.222|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801748.222|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 10)
[35mnode2_1          |[0m %7|1586801748.223|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 10, rtt 1.45ms)
[35mnode2_1          |[0m %7|1586801751.222|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801751.222|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 11)
[35mnode2_1          |[0m %7|1586801751.224|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 11, rtt 1.50ms)
[35mnode2_1          |[0m %7|1586801754.222|HEARTBEAT|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1001: Heartbeat for group "striot_con_group" generation id 1
[35mnode2_1          |[0m %7|1586801754.222|SEND|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Sent HeartbeatRequest (v3, 91 bytes @ 0, CorrId 12)
[35mnode2_1          |[0m %7|1586801754.225|RECV|rdkafka#consumer-1| [thrd:GroupCoordinator]: GroupCoordinator/1001: Received HeartbeatResponse (v3, 6 bytes, CorrId 12, rtt 2.81ms)
Gracefully stopping... (press Ctrl+C again to force)
